% Template for PLoS
% Version 3.5 March 2018
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended
% to minimize problems and delays during our production
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% Once your paper is accepted for publication,
% PLEASE REMOVE ALL TRACKED CHANGES in this file
% and leave only the final text of your manuscript.
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file.
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission.
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column.
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2".
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace}
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother



% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

% TODO: don't include graphics in the final version
\newcommand{\maybeincludegraphics}[1]{\includegraphics[width=\textwidth]{../data/figures/#1.png}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Multiple resolution nowcasting of influenza through sensor fusion} % Please use "sentence case" for title and headings (capitalize only the first word in a title (or heading), the first word in a subtitle (or subheading), and any proper nouns).
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\
David C. Farrow\textsuperscript{1},
% Anyone else? Feel free to edit.
Ryan J. Tibshirani\textsuperscript{2},
Roni Rosenfeld\textsuperscript{1,2}
\\
\bigskip
\textbf{1} Computational Biology Department, Carnegie Mellon University, Pittsburgh, PA, USA
\\
\textbf{2} Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA
\\
\bigskip

% Use the asterisk to denote corresponding authorship and provide email address in note below.
* roni.rosenfeld@cs.cmu.edu

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}

TODO

% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step.
% Author Summary not valid for PLOS ONE submissions.
\section*{Author summary}

Despite ongoing advances in public health, medicine, and related fields,
influenza remains an ever-present burden to modern society. One way in which
the impact of influenza outbreaks can be reduced is though greater situational
awareness, leading to improvements in prevention and preparedness. The advent
of digital surveillance and advances in the field of epidemiological
forecasting have given rise to a diverse set of noisy proxies of influenza
activity. It has been shown that a combination of several such proxies results
in increased signal-to-noise ratio and overall more accurate nowcasts at the US
national level. However, serious challenges remain in assimilating proxies
which vary in geographic resolution and which may be intermittently available.
To address these issues, we propose a sensor fusion approach to nowcasting
influenza. In agreement with previous results, we find that aggregate nowcasts
are overall more accurate than individual proxies. Furthermore, we produce
nowcasts at the level of US states, even though most proxies are only available
nationally or regionally. We make available ongoing, weekly nowcasts of
influenza activity in the US---nationally, regionally, and for all states.

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}

\subsection*{Background}

Annual influenza epidemics incur tremendous expenses and are strongly
detrimental to societal wellbeing \cite{szucs1999socio, Stohr2002,
molinari2007annual, who_flu_impact}. One way in which these impacts can be
lessened is though outbreak forewarning and therefore improved preparedness
\cite{myers2000}. This has been a primary impetus in the development of a large
number of influenza forecasting frameworks in recent years \cite{nsoesie2013a,
chretien2014, brooks2015, farrow2017human}. TODO(cite new brooks, cdc papers)

Forecasting critically depends on timely and accurate situational awareness,
and in the United States (US) one widespread measure of influenza burden is the
population-weighted percent influenza-like illness (wILI), derived from the US
Outpatient Influenza-Like Illness Surveillance Network (ILINet). On a weekly
basis, health care providers who have volunteered to participate in the ILINet
program submit, among other data, the percent of their cases that have met the
syndromic criteria of Influenza-Like Illness (\%ILI)---fever with either cough
or sore throat, without a known cause other than influenza \cite{wilidef,
who_ili_def}. The US Centers for Disease Control and Prevention (CDC) publishes
weekly wILI---a weighted combination of state \%ILI---for several locations
within the US, including the ten Health and Human Services (HHS) regions, the
nine census divisions, and the majority of US states and territories.

Although \%ILI, and by extension wILI, is highly beneficial in a number of
settings \cite{ritzwoller2005comparison, thompson2006epidemiology,
m2008infectious}, it is ill-suited for real-time estimation of influenza
activity for several reasons. First, there is an inherent delay of one or more
weeks between patient care and wILI availability. In the typical and best case,
data collected between Sunday and Saturday of some week is reported on Friday
of the following week. Second, wILI is subject to retrospective and significant
revision due to a process we refer to as ``backfill''. Backfill is the eventual
incorporation of reports submitted multiple weeks after patient care, and with
the additional data comes a different, but more representative, value of wILI.
Third, wILI is aggregated across broad geographic regions before publication.
It is well known, however, that the spread of influenza---particularly around
the peak of the epidemic---is spatially heterogeneous between and within states
\cite{bonabeau1998geographical, viboud2006synchrony, eggo2010spatial,
viboud2013contrasting, gog2014spatial}, and therefore regional, divisional, and
especially national wILI is a convolution of influenza activity within
constituent states.

\subsection*{Related Work}

An approach often used to address some of these issues is to incorporate novel
data streams (NDS) \cite{althouse2015enhancing}. These signals, when based on
search queries \cite{eysenbach2006infodemiology, polgreen2008using,
hulth2009web, ginsberg2009, dugas2013, araz2014using, santillana2014can,
preis2014adaptive}, social media \cite{ritterman2009, culotta2010towards,
signorini2011use, achrekar2011predicting, broniatowski2013national,
paul2014twitter}, information-seeking behavior \cite{generous2014global,
mciver2014wikipedia, hickmann2015forecasting}, and participatory surveillance
\cite{smolinski2015flu, chunara2013flu}, are collectively termed ``digital
surveillance'', as opposed to traditional surveillance of which wILI is one
example. Although many of these signals are available with little to no lag,
each has distinct shortcomings, and it seems that common practice has been to
nowcast wILI using any one of the available digital surveillance signals in
isolation. However, it was more recently demonstrated that multiple digital
surveillance signals can be used in parallel to produce more accurate nowcasts
of national wILI \cite{santillana2015combining}.

\subsection*{Contribution}

We propose nowcasting influenza through \emph{sensor
fusion}~\cite{farrow2016modeling} of digital surveillance. Derived from the
Kalman filter \cite{kalman1960new}, sensor fusion is optimal in a least-squares
sense (up to assumptions of independence and normality), robust to noise,
tolerant of missing data, and capable of assimilating data across varying
geospatial resolutions. We implement a sensor fusion framework and apply it to
nowcasting ILI in US states and territories (and in any combination thereof,
including HHS regions, census divisions, and the US as a whole), based on the
assimilation of any and all surveillance data available at runtime.

\section*{Materials and methods}

\subsection*{Data Sources}

Data sources used in nowcasting can be broadly separated into two classes:
ground truth and surveillance. The aim at any given point in time is to predict
ground truth, given surveillance. Surveillance can be further divided into
digital surveillance (e.g. based on social media) and predictive surveillance
(e.g. based on short-term forecasts). Below are the specific data sources we
use in each category.

\subsubsection*{Ground Truth}

\begin{description}
  \item{\textbf{Population weighted percent Influenza-like Illness (wILI)}} \\
    Each week, CDC publishes wILI for the US as a whole, the 10 HHS regions,
    the 9 census divisions, and most states and territories \cite{wilisrc}. In
    any given location, wILI is the mean (weighted by population) of ILI in
    constituent locations. ILI is the percent of influenza-like illness out of
    all patient visits voluntarily reported by participating healthcare
    providers. Because reports continue to be integrated after initial
    publication, wILI is subject to retrospective revision in a process we
    refer to as ``backfill''. As a result, wILI is effectively versioned. When
    training models and making predictions, we use preliminary---not
    final---values of wILI whenever possible.
\end{description}

\subsubsection*{Digital Surveillance}

\begin{description}
  \item{\textbf{Google Flu Trends (GFT)}} \\
    Google Flu Trends was a weekly prediction of wILI based on Google searches.
    The service was originally released in 2008; was updated in 2009, 2013, and
    2014 \cite{ginsberg2009, gft_main}; and was discontinued in 2015.
  \item{\textbf{Google Health Trends (GHT)}} \\
    Google Health Trends is an API by Google for research purposes which makes
    available, among many other things, daily counts (on an arbitrary scale)
    for a predefined influenza topic. TODO(link)
  \item{\textbf{HealthTweets (TWTR)}} \\
    HealthTweets (http://healthtweets.org) makes available the daily volume of
    tweets indicative of ILI \cite{broniatowski2013national,
    dredze2014healthtweets}.
  \item{\textbf{Wikimedia Foundation (WIKI)}} \\
    The Wikimedia Foundation makes available the number of hits, per hour, to
    every Wikipedia article. TODO(link)
  \item{\textbf{CDC Page Hits (CDCP)}} \\
    CDC makes available the number of daily hits per page, per state for their
    website (https:/www.cdc.gov/).
\end{description}

\subsubsection*{Predictive Surveillance}

\begin{description}
  \item{\textbf{Epicast (EPIC)}} \\
    Epicast \cite{farrow2017human} is an influenza forecasting system based on
    collective human judgment. From these forecasts, we interpret the
    one-week-ahead value of wILI as a nowcast. TODO(link)
  \item{\textbf{Seasonal Autoregression (SAR3)}} \\
    SAR3 \cite{farrow2016modeling} provides an autoregression estimate of wILI
    on the current week. TODO(link)
  \item{\textbf{Epidemic Archetype (ARCH)}} \\
    ARCH \cite{farrow2016modeling} is an empirical model based on the Empirical
    Bayes forecasting framework \cite{brooks2015}. Like Epicast, ARCH provides
    a short-term epidemiological forecast from which we interpret the
    one-week-ahead prediction as a nowcast.
\end{description}

With the exception of Google Health Trends, these data sources are publicly
available via the Delphi Epidata API. TODO(can we share TWTR? GHT?) TODO(link)

\subsection*{Fitting}

To obtain a signal usable for nowcasting, we must fit inputs to wILI. Since
this is trivially the case for predictive surveillance (i.e. EPIC, SAR3, and
ARCH), we use those values directly. For digital survaillance, we use
historical data to build a linear regression model mapping raw inputs to wILI.
We then apply this model with the most recent data to obtain a prediction of
wILI. We repeat the fitting procedure each week prior to nowcasting to obtain a
new model based on the most up-to-date data. The fitting procedure is described
in more detail in \cite{farrow2016modeling}.

Data sources with a single covariate (i.e. GFT, GHT, TWTR) are fit with
ordinary linear regression. Data sources with multiple covariates (i.e. WIKI,
CDCP) are fit with multiple linear regression.

As others have done for flu and other infectious diseases
\cite{generous2014global, hickmann2015forecasting, mciver2014wikipedia}, we use
the volume of Wikipedia traffic to estimate wILI for the US as a whole. To
produce a signal, we fit seven covariates to wILI, each corresponding to a
particular flu-releated Wikipedia article. The articles TODO(list in SI) were
chosen offline and by hand \textit{a priori}. Since WIKI has no attached
location information, we filter by particular hours of the day TODO(list in SI)
as a very rough proxy of Wikipedia activity in the US. Although this is a
grossly invalid assumption, preliminary investigation showed this to provide a
better fit to wILI.

Similarly, CDCP consists of six covariates, each corresponding to a particular
flu-releated page on the CDC website. The pages TODO(list in SI) were chosen
offline and by hand \textit{a priori}. CDCP is unique in that the covariates
are log-transformed before fitting as preliminary investigation showed this to
provide a better fit to wILI.

For all digital surveillance sources, we apply the fitting procedure separately
for each available location (e.g. US as a whole, HHS regions, census divisions,
and US states).

For data sources with sub-weekly temporal resolution (i.e. GHT, TWTR, WIKI,
CDCP), we aggregate counts by week before applying the fitting procedure. In
future work we aim to incorporate these sources as soon as they are available,
rather than waiting until the end of the week to use their aggregate values.

\subsection*{Fusion}

The fitting procedure described above gives a disparate set of predictions of
wILI for various locations in the US. We combine---via sensor fusion
\cite{farrow2016modeling}---all available predictions into a single, unified
nowcast of wILI throughout the US.

Sensor fusion is a generalization of the Kalman filter \cite{kalman1960new}
which relaxes assumptions regarding the process being tracked---the
distribution of wILI in this case. In particular, sensor fusion describes the
combination of a set of measurements without requiring a linear Markov process
model. This combination is optimal in a least-squares sense when the
measurements are unbiased with normally distributed error.

For nowcasting flu, this means practically that the fusion inputs should be in
the same units and on the same scale as wILI and should have normally
distributed error. By applying the fitting procedure above, we meet the first
requirement, and the assumption that errors are normally distributed is
generally not grossly violated.

Nowcasting is conceptually a two-step process. First, measurements are fused to
give an estimate of latent system state (namely, wILI in US states and
territories). Second, nowcasts for each location of interest (namely, wILI in
the US as a whole, HHS regions, census divisions, states, and territories) are
extracted as a linear combination of latent state wILI.

More concretely, given a vector of ``sensor`` readings (surveillance values as
described above) $z$, we apply the sensor fusion kernel to produce a vector
nowcast $y$.

\begin{align*}
A &= (H^T R^{-1} H)^{-1} H^T R^{-1} \\
x &= A z \\
y &= W x
\end{align*}

Elements of $z$ are the sensor reading of a particular data source in a
particular location, and elements of $y$ are a unified nowcast in each location
of interest.

Matrices $H$ and $W$ are mappings from latent state-space to measurement-space
and output-space respectively. Matrix $R$ is the empirical covariance of sensor
noise, where noise is defined as the difference between sensor readings and
ground truth measured on historical data. Intermediate matrix $A$ conceptually
represents the optimal translation from measurement-space to latent
state-space, given the reverse mapping ($H$) and sensor noise covariance ($R$).

$H$ and $W$ are defined by the geographical makeup and population distribution
within the US; they are constants, modulo changes in population over long
periods of time (e.g. years). On any given week, sensors $z$ are given by
surveillance data, and covariance $R$ is estimated based on historical data.

\subsection*{Covariance}

Given that multiple surveillance sources provide data at the level of US
states, the total number of source-location pairs (``sensors'') is well into
the hundreds. Their resulting covariance is very high-dimensional, especially
relative to the amount of weekly historical training data that is typically
available (e.g. a couple of years). Further, some data sources are only
available seasonally (i.e. EPIC, ARCH), and some are relatively lacking in
training data (i.e. CDCP, EPIC). In general, partial and missing data is a
possibility for any data source.

Estimating covariance in this situation is challenging, and the statistical
literature suggests several approaches \cite{bickel2008covariance,
ollerer2015robust, bien2011sparse, friedman2008sparse, bickel2008regularized,
hsieh2011sparse}. For speed and simplicity, we follow the guidance of
\cite{kolar2012consistent} for handling missing values and of
\cite{touloumis2015nonparametric} for regularization.

We begin by building a matrix of pair-wise empirical covariance. In this
matrix, the value of each element is computed as the covariance between a pair
of sensors. By filling the matrix, covariance is computed independently for all
sensor pairs. However, the resulting matrix does not necessarily describe
multi-dimensional covariance (i.e. it may not be positive definite), especially
with many missing values. To handle this, we shrink this matrix toward the
diagonal matrix of sensor variance. The magnitude of the shrinkage weight is
chosen to maximize the multivariate normal log-likelihood of the available
data. We subsequently use the shrunken matrix as $R$ in sensor fusion.

\subsection*{Evaluation}

In a given location over a given period of time, we assess the absolute
(scale-dependent) error of a nowcast by two measures: mean absolute error (MAE)
and root mean squared error (RMSE). With ground truth vector $\vec{x}$, nowcast
vector $\vec{y}$, and elements indexed by week $w$ of $n$, these measures are
defined as:

\begin{align*}
  \text{MAE} &= \frac{1}{n} \sum_{w=1}^n{\left|x_w - y_w\right|} \\
  \text{RMSE} &= \left( \frac{1}{n} \sum_{w=1}^n{\left(x_w - y_w\right)^2} \right)^\frac{1}{2}
\end{align*}

Although the units of ground truth (i.e. wILI) are the same in all locations,
the normal range of wILI varies between locations. To facilitate aggregation
and comparison among locations, we report several relative (scale-independent)
error measures with respect to various baselines. Each of these is computed by
normalizing nowcast error by the same type of error measured on the output of a
baseline model. Here we define two such baseline models: ``naive'' and
``simple''.

Because wILI is subject to revision over multiple months, a real-time naive
nowcast would be defined as \textit{preliminary} wILI on the preceding week.
However, preliminary versions of wILI are not generally known today (except for
within a narrow set of locations and seasons). As a result, we introduce a
``naive oracle'' nowcaster. This assumes (incorrectly) that the final version
of wILI is known with no delay and defines the naive nowcast as \textit{final}
wILI on the preceding week. Since this information is not available at runtime,
the naive baseline is unfairly advantaged.

The ``simple'' baseline is defined as the median of all sensor readings for a
given location, ignoring sensor readings elsewhere. This is in effect a wisdom
of the crowd nowcast that doesn't incorporate information from outside
locations.

We report MAE of nowcasts relative to MAE of each baseline (RelMAE TODO(cite)).
In doing so with the ``naive'' baseline, this is a special case of RelMAE known
as mean absolute scaled error (MASE) \cite{hyndman2006another}. MASE is defined
in the context of time-series forecasting in general as the MAE of a given
forecast normalized by the MAE of an in-sample, one-step naive forecast.

Using the same notation as above, assuming $\tilde{z}_w$ represents the median
sensor reading for the current location on week $w$, and considering the $m$
weeks for which ground truth is available on the prior week, these measures are
defined as:

\begin{align*}
  \text{RelMAE} &= \text{MAE} \left( \frac{1}{n} \sum_{w=1}^n{\left|x_w - \tilde{z}_w\right|} \right) ^ {-1} \\
  \text{MASE} &= \text{MAE} \left( \frac{1}{m} \sum_{w=1}^m{\left|x_w - x_{w - 1}\right|} \right) ^ {-1}
\end{align*}

% Results and Discussion can be combined.
\section*{Results}

\subsection*{Sensors}

% python3 analyze.py sensor_info
% gft:
%   num national: 254
%   first week: 201040
%   last week: 201532
%   num locations: 62
% ght:
%   num national: 402
%   first week: 201040
%   last week: 201824
%   num locations: 52
% twtr:
%   num national: 339
%   first week: 201151
%   last week: 201824
%   num locations: 71
% wiki:
%   num national: 402
%   first week: 201040
%   last week: 201824
%   num locations: 1
% cdc:
%   num national: 276
%   first week: 201310
%   last week: 201824
%   num locations: 71
% epic:
%   num national: 119
%   first week: 201442
%   last week: 201819
%   num locations: 15
% sar3:
%   num national: 402
%   first week: 201040
%   last week: 201824
%   num locations: 75
% arch:
%   num national: 265
%   first week: 201040
%   last week: 201820
%   num locations: 20
% total num readings: 113164

In total, we obtained 113,164 individual sensor readings from the eight
surveillance sources discussed above. Table~\ref{table_sensor_breakdown} gives
a breakdown of the number of weeks and locations covered by each source.
Fig~\ref{figure_sensor_heatmap} shows time-series of sensor readings for the US
as a whole, which is the only location common to all data sources.

\begin{table}[!ht]
  \centering
  \caption{{\bf Sensor coverage across time and location.}}
  \begin{tabular}{|l|l|l|}
    \hline
    {\bf Source} & {\bf Weeks} & {\bf Locations}\\ \thickhline
    GFT & 254 & 62 \\ \hline
    GHT & 402 & 52 \\ \hline
    TWTR & 339 & 71 \\ \hline
    WIKI & 402 & 1 \\ \hline
    CDCP & 276 & 71 \\ \hline
    EPIC & 119 & 15 \\ \hline
    SAR3 & 402 & 75 \\ \hline
    ARCH & 265 & 20 \\ \hline
  \end{tabular}
  \label{table_sensor_breakdown}
\end{table}

\begin{figure}[!ht]
  \maybeincludegraphics{sensor_heatmap}
  \caption{
    {\bf National sensor readings fitted from eight data sources.}
    Top: Plot of sensor readings (colors) and ground truth wILI (black) over
    time, highlighting sensor noise.
    Bottom: Heatmap of sensor readings over time, highlighting sensor
    intermittency.
  }
  \label{figure_sensor_heatmap}
\end{figure}

\subsection*{Nowcasts}

% python3 analyze.py nowcast_info
% num national nowcasts: 397
% first week: 201045
% last week: 201824
% total num nowcasts: 29103
% num locations: 75

In total, we produced 29,103 nowcasts for 75 US locations across 397 weeks
spanning 2010w45--2018w24. Locations include the US as a whole, the 10 HHS
regions, the 9 census divisions, the 50 states, the District of Columbia,
Puerto Rico, the US Virgin Islands, New York City, and New York state
\textit{excluding} New York City. Fig~\ref{figure_all_nowcasts} shows a
time-series comparison of all nowcasts with ground truth. Although these
nowcasts were computed in retrospect, models were trained whenever possible
using only data that would have been available at the time. For any given week,
preliminary values of wILI (when known) were used in place of final values, and
data from future weeks was held out.

\begin{figure}[!ht]
  \maybeincludegraphics{all_nowcasts}
  \caption{
    {\bf Nowcasts compared with ground truth.}
    Each subpanel contains a plot of nowcast (color) and ground truth (black)
    in a particular location within the US. All subplots share the same scale
    in both time and magnitude.
  }
  \label{figure_all_nowcasts}
\end{figure}

\subsubsection*{Accuracy relative to data sources}

For the US as a whole, Fig~\ref{figure_accuracy_vs_sensors} compares error
(measured in MAE and RMSE) between nowcasts and individual data sources. To
control for the fact that difficulty varies over time, the evaluation is
performed only over weeks on which the nowcast and the particular data source
are jointly available. The number of weeks in each such union is indicated in
each corresponding subpanel.

\begin{figure}[!ht]
  \maybeincludegraphics{accuracy_vs_sensors}
  \caption{
    {\bf Nowcast error compared with sensor error.}
    TODO: explain this
  }
  \label{figure_accuracy_vs_sensors}
\end{figure}

In all instances, the nowcast has lower error (both MAE and RMSE) than any
individual data source after applying the fitting procedure described above. This
indicates, at least for the US as a whole, that the nowcast is on average more
accurate than any individual data source (at least for this particular fitting
procedure).

\subsubsection*{Accuracy relative to baselines}

To assess accuracy at finer geographic resolutions, we report MAE relative to
the naive and simple baselines (measured as the ratios MASE and RelMAE
respectively). When aggregating errors over multiple geographic units (e.g.
states within some region) we report the geometric mean of errors as this
yields a result that can still be interpreted as a ratio. The relative errors
are summarized in Table~\ref{table_relative_metrics}.

% python3 analyze.py metrics
\begin{table}[!ht]
  \centering
  \caption{{\bf Relative error across sets of locations.}}
  \begin{tabular}{|l|l|l|}
    \hline
    {\bf Locations (n)} & {\bf G.M. MASE} & {\bf G.M. RelMAE}\\ \thickhline
    US National (1) & 0.667 & 0.799 \\ \hline
    Census Divisions (9) & 0.853 & 0.859 \\ \hline
    HHS Regions (10) & 0.865 & 0.849 \\ \hline
    Atoms in HHS1 (6) & 0.960 & 0.918 \\ \hline
    Atoms in HHS2 (5) & 1.094 & 1.068 \\ \hline
    Atoms in HHS3 (6) & 1.019 & 0.900 \\ \hline
    Atoms in HHS4 (8) & 0.996 & 0.886 \\ \hline
    Atoms in HHS5 (6) & 0.955 & 0.912 \\ \hline
    Atoms in HHS6 (5) & 0.941 & 0.941 \\ \hline
    Atoms in HHS7 (4) & 0.995 & 0.928 \\ \hline
    Atoms in HHS8 (6) & 1.029 & 0.991 \\ \hline
    Atoms in HHS9 (4) & 1.048 & 0.863 \\ \hline
    Atoms in HHS10 (4) & 1.014 & 0.929 \\ \hline
    All Atoms (54) & 1.002 & 0.931 \\ \hline
  \end{tabular}
  \begin{flushleft}
    TODO(define atom, enumerate "all atoms", mention naive/simple, define GM)
  \end{flushleft}
  \label{table_relative_metrics}
\end{table}

At the national level, the sensor fusion nowcast has lower error than either
baseline by a considerable margin. The same is true for Census divisions and
HHS regions collectively, although the margin is not as large. Aggregated over
individual atoms, either within a particular region or altogether, the sensor
fusion nowcast seems to generally be on par with the naive baseline and
somewhat better than the simple baseline. For atoms within HHS region 2
specifically, the sensor fusion nowcast has higher overall error than both
naive and simple baselines.

\subsubsection*{Sensitivity to each data source}

Digital surveillance is intermittent by nature, and data sources are subject to
sporadic, periodic (e.g. EPIC), and permanent (e.g. GFT) periods of
absence. We expect sensor fusion to gracefully handle these cases, but it is
not immediately clear what impact the absence of a given data source has on the
quality of the resulting nowcast.

To explore this question, we compare accuracy of nowcasts with and without each
data source in a set of eight ``ablation'' experiments in
Fig~\ref{figure_accuracy_vs_ablation}. For a given data source, we compute the
US national nowcast with and without that source and compare error in terms of
MAE and RMSE. Since the difficulty of nowcasting varies over time, we restrict
these comparisons to the set of weeks on which a particular data source (or,
more accurately, its fitted sensors) are available.

\begin{figure}[!ht]
  \maybeincludegraphics{accuracy_vs_ablation}
  \caption{
    {\bf Nowcast error compared with and without each data source.}
    TODO: explain this
  }
  \label{figure_accuracy_vs_ablation}
\end{figure}

As expected, we generally find that removal of a particular data source causes
an increase (or, in the case of WIKI, no meaningful change) in nowcasting
error. However, there are a couple of exceptions: TWTR and CDC. Nowcasting
error \textit{decreases} when removing these data sources. This is unexpected
in theory and strongly suggests violated assumptions (e.g. the relationship of
these sources with wILI may be nonlinear or residuals may not be normally
distributed) or overfitting (e.g. covariance may be underestimated for these
sources) in practice.

\subsubsection*{Sensitivity to geographic resolution}

A related question is to what extent the inclusion of geographic ``tiers''
impacts accuracy of nowcasts. Namely, is it helpful for nowcasting the US
nationally to include data at the level of regions, states, cities, and
territories?

To answer this, we similarly compare nowcasting error in terms of MAE and RMSE
with and without data at regional (Census and HHS) and state (including cities
and territories) levels. This is difficult to assess for all data sources,
given that many do not include data at the level of states (or even regions, in
the case of WIKI). Because of this, we limit the set of data sources to only
those available at the level of states (and above): GFT, GHT, TWTR, CDCP, and
SAR3. Again, we restrict the comparison to weeks on which sensors are mutually
available. The results of these comparisons are summarized in
Fig~\ref{figure_accuracy_vs_abscission}.

\begin{figure}[!ht]
  \maybeincludegraphics{accuracy_vs_abscission}
  \caption{
    {\bf Nowcast error compared across geographic tiers.}
    TODO: explain this
  }
  \label{figure_accuracy_vs_abscission}
\end{figure}

Between national-only and national-and-regional nowcasts, we see an increase in
accuracy (a decrease in both MAE and RMSE), suggesting that higher geographic
resolution is beneficial to the nowcast. When including all locations, MAE
further decreases, but RMSE increases. One possible reason for this mixed
result is poor model fitting (i.e. covariance estimation) induced by a large
increase in dimensionality with no increase in the number of weekly sensor
observations.

\section*{Discussion}

We compared nowcasts with two baselines; a naive oracle, which reports
finalized wILI on the previous week, and a simple method, which reports the
median sensor reading on a given week. At high geographic resolution (i.e.
states, territories, and cities), we find that sensor fusion nowcasts are
cumulatively approximately on par with naive oracle nowcasts and somewhat
better than simple nowcasts. At lower geographic resolution (i.e. regionally
and nationally), sensor fusion nowcasts strongly and uniformly outperform both
baselines.

MASE---error of sensor fusion nowcasts relative to error of the naive
oracle---is frequently greater than one in small geographic units, indicating
that the nowcast under consideration performed \textit{worse} than the
so-called ``naive'' nowcast. This result is not entirely unexpected, given that
the naive oracle incorporates latent information (namely, finalized ILI) which
is unavailable to operational nowcasts at runtime.

That the nowcast is more accurate than its individual inputs (i.e. ``sensors'')
should hold in general as the outputs of sensor fusion should, on average, have
smaller error than the inputs. Overfitting or violations of the assumptions of
linearity and normality may cause deviations from this expectation.

We observe such deviations at least twice. First, for the set of five states,
territories, and cities within HHS region two (``HHS2''), we find that the
geometric mean of RelMAE---error of sensor fusion nowcasts relative to error of
the simple baseline---is greater than one, meaning that the baseline
outperformed the nowcast in these locations. Second, we find that removal of
certain sensors (``ablation'' and ``abscission'' experiments) causes the
accuracy of the nowcast to improve. In both of these situations, less data is
better than more data, against expectation.

Our estimate of the covariance of sensor ``noise'' (residuals w.r.t. ground
truth) $R$ is necessarily imperfect. Adding additional sensors exponentially
increases the dimension of the problem without adding new observations---the
curse of dimensionality. With up to 363 sensor-location pairs, $R$ has shape
$363 \times 363$; yet in the best case we only have a few hundred observations
from which to estimate this covariance---often much fewer. Our only recourse is
aggressive regularization at the expense of covariance accuracy, and therefore
nowcast accuracy.

Linearity between sensors and ground truth and normality of sensor noise are
each merely assumed. Violations of these assumptions are neither tested for nor
acted upon. The sensor fitting procedure simply centers and scales raw data to
fit ground truth in a least-squares sense. It is possible, if not likely, that
some sensors are nonlinear w.r.t. ground truth or have non-normal residuals (or
both). When this is the case, nowcasts will be less accurate; sensor fusion, at
least as formulated above, operates in terms of linear combinations of
multivariate normal distributions.

Additionally, we make the implicit assumption that the relationship between
each sensor and ground truth is constant over time. That is, we assume that the
bias and variance of residuals are fixed. (In contrast, we explicitly account
for a time-varying relationship between raw data and ground truth in the sensor
fitting procedure.) However, this is almost certainly violated in some
situations; for example, digital surveillance is disproportionately affected
during periods of heightened traditional and social media coverage of
outbreaks.

TODO(why is hhs2 the worst? PR/VI: least ground truth, extreme noise, disparate
dynamics, no sensors other than sar3; NY, JFK: inferred.)

TODO: merits and drawbacks of sensor fusion

\section*{Conclusion}

TODO

\section*{Supporting information}

\paragraph*{S1 Text}
\label{S1_Text}
{\bf Supporting Information.} Derivation of the sensor fusion kernel.

\section*{Acknowledgments}

TODO

\nolinenumbers

% Compile your BiBTeX database using our plos2015.bst
% style file and paste the contents of your .bbl file
% here. See http://journals.plos.org/plosone/s/latex for
% step-by-step instructions.

% Uncomment this to generate the *.bbl file.
%\bibliography{references}

% Paste the contents of the *.bbl file below this line.
\begin{thebibliography}{10}

\bibitem{szucs1999socio}
Szucs T.
\newblock The socio-economic burden of influenza.
\newblock Journal of Antimicrobial Chemotherapy. 1999;44(suppl 2):11--15.

\bibitem{Stohr2002}
St{\"o}hr K.
\newblock Influenza--WHO cares.
\newblock The Lancet Infectious diseases. 2002;2(9):517--517.

\bibitem{molinari2007annual}
Molinari NAM, Ortega-Sanchez IR, Messonnier ML, Thompson WW, Wortley PM,
  Weintraub E, et~al.
\newblock The annual impact of seasonal influenza in the US: measuring disease
  burden and costs.
\newblock Vaccine. 2007;25(27):5086--5096.

\bibitem{who_flu_impact}
Influenza (Seasonal); 2018.
\newblock Available from:
  \url{http://www.who.int/mediacentre/factsheets/fs211/en/}.

\bibitem{myers2000}
Myers MF, Rogers D, Cox J, Flahault A, Hay S.
\newblock Forecasting disease risk for increased epidemic preparedness in
  public health.
\newblock Advances in Parasitology. 2000;47:309--330.

\bibitem{nsoesie2013a}
Nsoesie EO, Brownstein JS, Ramakrishnan N, Marathe MV.
\newblock A systematic review of studies on forecasting the dynamics of
  influenza outbreaks.
\newblock Influenza Other Respi Viruses. 2013;8(3):309--316.
\newblock doi:{10.1111/irv.12226}.

\bibitem{chretien2014}
Chretien JP, George D, Shaman J, Chitale RA, McKenzie FE.
\newblock Influenza Forecasting in Human Populations: A Scoping Review.
\newblock {PLoS} {ONE}. 2014;9(4):e94130.
\newblock doi:{10.1371/journal.pone.0094130}.

\bibitem{brooks2015}
Brooks LC, Farrow DC, Hyun S, Tibshirani RJ, Rosenfeld R.
\newblock Flexible Modeling of Epidemics with an Empirical Bayes Framework.
\newblock {PLOS} Computational Biology. 2015;11(8):e1004382.
\newblock doi:{10.1371/journal.pcbi.1004382}.

\bibitem{farrow2017human}
Farrow DC, Brooks LC, Hyun S, Tibshirani RJ, Burke DS, Rosenfeld R.
\newblock A human judgment approach to epidemiological forecasting.
\newblock PLOS Computational Biology. 2017;13(3):e1005248.

\bibitem{wilidef}
Overview of Influenza Surveillance in the United States; 2015.
\newblock Available from: \url{http://www.cdc.gov/flu/weekly/overview.htm}.

\bibitem{who_ili_def}
WHO surveillance case definitions for ILI and SARI; 2014.
\newblock Available from:
  \url{http://www.who.int/influenza/surveillance_monitoring/ili_sari_surveillance_case_definition/en/}.

\bibitem{ritzwoller2005comparison}
Ritzwoller DP, Kleinman K, Palen T, Abrams A, Kaferly J, Yih W, et~al.
\newblock Comparison of syndromic surveillance and a sentinel provider system
  in detecting an influenza outbreak—Denver, Colorado, 2003.
\newblock MMWR Morb Mortal Wkly Rep. 2005;54(Suppl.):151--6.

\bibitem{thompson2006epidemiology}
Thompson WW, Comanor L, Shay DK.
\newblock Epidemiology of seasonal influenza: use of surveillance data and
  statistical models to estimate the burden of disease.
\newblock Journal of Infectious Diseases. 2006;194(Supplement 2):S82--S91.

\bibitem{m2008infectious}
M'ikanatha NM, Lynfield R, Van~Beneden CA, de~Valk H.
\newblock Infectious disease surveillance.
\newblock John Wiley \& Sons; 2008.

\bibitem{bonabeau1998geographical}
Bonabeau E, Toubiana L, Flahault A.
\newblock The geographical spread of influenza.
\newblock Proceedings of the Royal Society of London B: Biological Sciences.
  1998;265(1413):2421--2425.

\bibitem{viboud2006synchrony}
Viboud C, Bj{\o}rnstad ON, Smith DL, Simonsen L, Miller MA, Grenfell BT.
\newblock Synchrony, waves, and spatial hierarchies in the spread of influenza.
\newblock science. 2006;312(5772):447--451.

\bibitem{eggo2010spatial}
Eggo RM, Cauchemez S, Ferguson NM.
\newblock Spatial dynamics of the 1918 influenza pandemic in England, Wales and
  the United States.
\newblock Journal of The Royal Society Interface. 2010; p. rsif20100216.

\bibitem{viboud2013contrasting}
Viboud C, Nelson MI, Tan Y, Holmes EC.
\newblock Contrasting the epidemiological and evolutionary dynamics of
  influenza spatial transmission.
\newblock Philosophical Transactions of the Royal Society of London B:
  Biological Sciences. 2013;368(1614):20120199.

\bibitem{gog2014spatial}
Gog JR, Ballesteros S, Viboud C, Simonsen L, Bjornstad ON, Shaman J, et~al.
\newblock Spatial transmission of 2009 pandemic influenza in the US.
\newblock PLoS Comput Biol. 2014;10(6):e1003635.

\bibitem{althouse2015enhancing}
Althouse BM, Scarpino SV, Meyers LA, Ayers JW, Bargsten M, Baumbach J, et~al.
\newblock Enhancing disease surveillance with novel data streams: challenges
  and opportunities.
\newblock EPJ Data Science. 2015;4(1):1--8.

\bibitem{eysenbach2006infodemiology}
Eysenbach G.
\newblock Infodemiology: tracking flu-related searches on the web for syndromic
  surveillance.
\newblock In: AMIA Annual Symposium Proceedings. vol. 2006. American Medical
  Informatics Association; 2006. p. 244.

\bibitem{polgreen2008using}
Polgreen PM, Chen Y, Pennock DM, Nelson FD, Weinstein RA.
\newblock Using internet searches for influenza surveillance.
\newblock Clinical infectious diseases. 2008;47(11):1443--1448.

\bibitem{hulth2009web}
Hulth A, Rydevik G, Linde A.
\newblock Web queries as a source for syndromic surveillance.
\newblock PloS one. 2009;4(2):e4378.

\bibitem{ginsberg2009}
Ginsberg J, Mohebbi MH, Patel RS, Brammer L, Smolinski MS, Brilliant L.
\newblock Detecting influenza epidemics using search engine query data.
\newblock Nature. 2009;457(7232):1012--1014.

\bibitem{dugas2013}
Dugas AF, Jalalpour M, Gel Y, Levin S, Torcaso F, Igusa T, et~al.
\newblock Influenza Forecasting with Google Flu Trends.
\newblock {PLoS} {ONE}. 2013;8(2):e56176.
\newblock doi:{10.1371/journal.pone.0056176}.

\bibitem{araz2014using}
Araz OM, Bentley D, Muelleman RL.
\newblock Using Google Flu Trends data in forecasting influenza-like--illness
  related ED visits in Omaha, Nebraska.
\newblock The American journal of emergency medicine. 2014;32(9):1016--1023.

\bibitem{santillana2014can}
Santillana M, Zhang DW, Althouse BM, Ayers JW.
\newblock What can digital disease detection learn from (an external revision
  to) Google Flu Trends?
\newblock American journal of preventive medicine. 2014;47(3):341--347.

\bibitem{preis2014adaptive}
Preis T, Moat HS.
\newblock Adaptive nowcasting of influenza outbreaks using Google searches.
\newblock Royal Society open science. 2014;1(2):140095.

\bibitem{ritterman2009}
Ritterman J, Osborne M, Klein E.
\newblock Using prediction markets and Twitter to predict a swine flu pandemic.
\newblock In: 1st international workshop on mining social media. vol.~9. ac.
  uk/miles/papers/swine09. pdf (accessed 26 August 2015); 2009. p. 9--17.

\bibitem{culotta2010towards}
Culotta A.
\newblock Towards detecting influenza epidemics by analyzing Twitter messages.
\newblock In: Proceedings of the first workshop on social media analytics. ACM;
  2010. p. 115--122.

\bibitem{signorini2011use}
Signorini A, Segre AM, Polgreen PM.
\newblock The use of Twitter to track levels of disease activity and public
  concern in the US during the influenza A H1N1 pandemic.
\newblock PloS one. 2011;6(5):e19467.

\bibitem{achrekar2011predicting}
Achrekar H, Gandhe A, Lazarus R, Yu SH, Liu B.
\newblock Predicting flu trends using twitter data.
\newblock In: Computer Communications Workshops (INFOCOM WKSHPS), 2011 IEEE
  Conference on. IEEE; 2011. p. 702--707.

\bibitem{broniatowski2013national}
Broniatowski DA, Paul MJ, Dredze M.
\newblock National and local influenza surveillance through Twitter: an
  analysis of the 2012-2013 influenza epidemic.
\newblock PloS one. 2013;8(12):e83672.

\bibitem{paul2014twitter}
Paul MJ, Dredze M, Broniatowski D.
\newblock Twitter improves influenza forecasting.
\newblock PLoS currents. 2014;6.

\bibitem{generous2014global}
Generous N, Fairchild G, Deshpande A, Del~Valle SY, Priedhorsky R.
\newblock Global disease monitoring and forecasting with Wikipedia.
\newblock PLoS Comput Biol. 2014;10(11):e1003892.

\bibitem{mciver2014wikipedia}
McIver DJ, Brownstein JS.
\newblock Wikipedia usage estimates prevalence of influenza-like illness in the
  United States in near real-time.
\newblock PLoS Comput Biol. 2014;10(4):e1003581.

\bibitem{hickmann2015forecasting}
Hickmann KS, Fairchild G, Priedhorsky R, Generous N, Hyman JM, Deshpande A,
  et~al.
\newblock Forecasting the 2013--2014 influenza season using Wikipedia.
\newblock PLoS Comput Biol. 2015;11(5):e1004239.

\bibitem{smolinski2015flu}
Smolinski MS, Crawley AW, Baltrusaitis K, Chunara R, Olsen JM, W{\'o}jcik O,
  et~al.
\newblock Flu Near You: Crowdsourced Symptom Reporting Spanning 2 Influenza
  Seasons.
\newblock American journal of public health. 2015;105(10):2124--2130.

\bibitem{chunara2013flu}
Chunara R, Aman S, Smolinski M, Brownstein JS.
\newblock Flu near you: an online self-reported influenza surveillance system
  in the USA.
\newblock Online Journal of Public Health Informatics. 2013;5(1).

\bibitem{santillana2015combining}
Santillana M, Nguyen AT, Dredze M, Paul MJ, Nsoesie EO, Brownstein JS.
\newblock Combining search, social media, and traditional data sources to
  improve influenza surveillance.
\newblock PLoS Comput Biol. 2015;11(10):e1004513.

\bibitem{farrow2016modeling}
Farrow DC.
\newblock Modeling the Past, Present, and Future of Influenza [PhD Thesis].
\newblock Carnegie Mellon University; 2016.
\newblock Available from:
  \url{http://reports-archive.adm.cs.cmu.edu/anon/cbd/CMU-CB-16-101.pdf}.

\bibitem{kalman1960new}
Kalman RE.
\newblock A new approach to linear filtering and prediction problems.
\newblock Journal of basic Engineering. 1960;82(1):35--45.

\bibitem{wilisrc}
Influenza National and Regional Level Graphs and Data; 2017.
\newblock Available from:
  \url{https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html}.

\bibitem{gft_main}
Google Flu Trends; 2015.
\newblock Available from: \url{https://www.google.org/flutrends/about/}.

\bibitem{dredze2014healthtweets}
Dredze M, Cheng R, Paul MJ, Broniatowski D.
\newblock HealthTweets.org: a platform for public health surveillance using
  twitter.
\newblock In: AAAI Conference on Artificial Intelligence; 2014. p. 1--2.

\bibitem{bickel2008covariance}
Bickel PJ, Levina E.
\newblock Covariance regularization by thresholding.
\newblock The Annals of Statistics. 2008; p. 2577--2604.

\bibitem{ollerer2015robust}
{\"O}llerer V, Croux C.
\newblock Robust high-dimensional precision matrix estimation.
\newblock In: Modern Nonparametric, Robust and Multivariate Methods. Springer;
  2015. p. 325--350.

\bibitem{bien2011sparse}
Bien J, Tibshirani RJ.
\newblock Sparse estimation of a covariance matrix.
\newblock Biometrika. 2011;98(4):807--820.

\bibitem{friedman2008sparse}
Friedman J, Hastie T, Tibshirani R.
\newblock Sparse inverse covariance estimation with the graphical lasso.
\newblock Biostatistics. 2008;9(3):432--441.

\bibitem{bickel2008regularized}
Bickel PJ, Levina E.
\newblock Regularized estimation of large covariance matrices.
\newblock The Annals of Statistics. 2008; p. 199--227.

\bibitem{hsieh2011sparse}
Hsieh CJ, Dhillon IS, Ravikumar PK, Sustik MA.
\newblock Sparse inverse covariance matrix estimation using quadratic
  approximation.
\newblock In: Advances in Neural Information Processing Systems; 2011. p.
  2330--2338.

\bibitem{kolar2012consistent}
Kolar M, Xing EP.
\newblock Consistent covariance selection from data with missing values.
\newblock In: Proceedings of the 29th International Conference on Machine
  Learning (ICML-12); 2012. p. 551--558.

\bibitem{touloumis2015nonparametric}
Touloumis A.
\newblock Nonparametric Stein-type shrinkage covariance matrix estimators in
  high-dimensional settings.
\newblock Computational Statistics \& Data Analysis. 2015;83:251--261.

\bibitem{hyndman2006another}
Hyndman RJ, Koehler AB.
\newblock Another look at measures of forecast accuracy.
\newblock International journal of forecasting. 2006;22(4):679--688.

\end{thebibliography}
% Paste the contents of the *.bbl file above this line.

\end{document}
